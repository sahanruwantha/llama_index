{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/embeddings/nebius.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nebius Embeddings\n",
    "\n",
    "This notebook demonstrates how to use [Nebius AI Studio](https://studio.nebius.ai/) Embeddings with LlamaIndex. Nebius AI Studio implements all state-of-the-art embeddings models, available for commercial use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install LlamaIndex and dependencies of Nebius AI Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-embeddings-nebius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your Nebius AI Studio key below. You can get it by registering for free at [Nebius AI Studio](https://auth.eu.nebius.com/ui/login) and issuing the key at [API Keys section](https://studio.nebius.ai/settings/api-keys).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEBIUS_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get embeddings using Nebius AI Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.nebius import NebiusEmbedding\n",
    "\n",
    "embed_model = NebiusEmbedding(api_key=NEBIUS_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "[-0.002410888671875, 0.0083770751953125, -0.00542449951171875, 0.007366180419921875, -0.022216796875]\n"
     ]
    }
   ],
   "source": [
    "text = \"Everyone loves justice at another person's expense\"\n",
    "embeddings = embed_model.get_text_embedding(text)\n",
    "assert len(embeddings) == 4096\n",
    "print(len(embeddings), embeddings[:5], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "[-0.002410888671875, 0.0083770751953125, -0.00542449951171875, 0.007366180419921875, -0.022216796875]\n"
     ]
    }
   ],
   "source": [
    "text = \"Everyone loves justice at another person's expense\"\n",
    "embeddings = await embed_model.aget_text_embedding(text)\n",
    "assert len(embeddings) == 4096\n",
    "print(len(embeddings), embeddings[:5], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0003886222839355469, 0.0004887580871582031, 0.011199951171875]\n",
      "[-0.003734588623046875, 0.01143646240234375, 0.008758544921875]\n",
      "[0.005901336669921875, 0.005161285400390625, 0.00142669677734375]\n",
      "[-0.00946807861328125, -0.0048675537109375, 0.004817962646484375]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"As the hours pass\",\n",
    "    \"I will let you know\",\n",
    "    \"That I need to ask\",\n",
    "    \"Before I'm alone\",\n",
    "]\n",
    "\n",
    "embeddings = embed_model.get_text_embedding_batch(texts)\n",
    "assert len(embeddings) == 4\n",
    "assert len(embeddings[0]) == 4096\n",
    "print(*[x[:3] for x in embeddings], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async batched usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0003886222839355469, 0.0004887580871582031, 0.011199951171875]\n",
      "[-0.003734588623046875, 0.01143646240234375, 0.008758544921875]\n",
      "[0.005901336669921875, 0.005161285400390625, 0.00142669677734375]\n",
      "[-0.00946807861328125, -0.0048675537109375, 0.004817962646484375]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"As the hours pass\",\n",
    "    \"I will let you know\",\n",
    "    \"That I need to ask\",\n",
    "    \"Before I'm alone\",\n",
    "]\n",
    "\n",
    "embeddings = await embed_model.aget_text_embedding_batch(texts)\n",
    "assert len(embeddings) == 4\n",
    "assert len(embeddings[0]) == 4096\n",
    "print(*[x[:3] for x in embeddings], sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
